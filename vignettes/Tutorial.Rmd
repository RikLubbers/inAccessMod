---
title: "Tutorial"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(inAccessMod)
```

### Description
This package allows us to easily prepare all the required layers for AccessMod. A proper folder structure is created in order to manage multi-temporal data and/or multiple analysis scenarios. While the functions to process health facility tables are specifically designed to handle HeRAMS data, the other ones can be used for any other project. The downloading, cropping, masking, resampling and exporting processes are automated to a large degree, making the preparation of the inputs quick and straightforward.

### Installation
First, we make sure that the devtools package installed on our computer.
```{r devtools, eval=FALSE}
if (!require("devtools")) install.packages("devtools")
```

Then we use its *install_github* function to download and install the **inAccessMod** package from its github repository.

```{r install, eval=FALSE}
devtools::install_github("ptimoner/inAccessMod")
```

Once it is installed, we can load the package in order to make its functions directly available.

```{r library, message=FALSE}
library(inAccessMod)
```

### Initiate Project
With the *initiate_project* function, we can select the country and automatically, the ISO 3166-1 alpha-3 country code is stored in a config.txt file and the directory main structure for the project is created. This function also creates a log.txt file that will record and track the main operations related to the project. We will see that the final structure arises when downloading and processing the data with the corresponding functions, and it allows multiple ’raw’ inputs and multiple ’processed’ outputs for each input. This can be useful when performing different analyses for the same country (e.g. when we have updated data) or using different processing parameters. While all usual inputs can be automatically downloaded using this package (except the health facilities), we still can add data manually. For instance we would like to use a different population raster than the ones provided by WorldPop which is the population raster server used here, we could use the *copy_input* function to copy any input downloaded manually into an appropriate sub-folder for further processing.

To initiate the project, the only parameter we need to provide is the path where the project, namely the country folder will be created.

```{r initiate, eval=FALSE}
mainPath <- "C:/inAccessMod/tutorial"
initiate_project(mainPath)
```

![](initiate.png)

As indicated in the console, some input folders are created by default. We are asked if we want to add another input folder. Let's say that it is not necessary. This is how the new directories look like in a tree-like format. Further, we will see how this tree can grow with the downloading and the processing of inputs.

![](initiate2.png)

### Download the country boundaries

Now, that the project is initiated, we can download the country boundary layer with the *download_boundaries* function. This layer will help to set the projected coordinate reference system and will be used for cropping, masking and clipping the other input layers. The function requires the name of the country folder, the boundary administrative level and a logical parameter (TRUE/FALSE) that indicates if the layer should always be downloaded, even if it has already been downloaded. If FALSE and if the administrative boundary shapefile has already been downloaded we are interactively asked whether we want to download it again or not. The layer is downloaded from the *geoboundaries* database. If the the administrative level is not available, the function tries a lower one and so on. Metadata file is also downloaded.

```{r boundaries, eval=FALSE}
country <- "Switzerland"
download_boundaries(mainPath, country, adminLevel = 4, alwaysDownload = TRUE)
```

### Set the projected coordinate reference system

Now, we will set the projected coordinate reference system with the *set_projection* function. The "best-fit" and the suitable projected coordinate reference systems are obtained with the *suggest_top_crs* and the *suggest_crs* functions, respectively, from the **crsuggest** package. Both functions work by analyzing the extent of the spatial layer and comparing it to the area extents in the EPSG's coordinate reference system database. By setting *bestCRS* = TRUE, the reference system is set based on the "best-fit" system? If FALSE, we are interactively asked to select the projected coordinate reference system from a list of the suitable reference systems. It has to be noted that the reference system is set for the entire project. If it is modified after having processed some input layers, we have to make sure to process these inputs again. The logical parameter *mostRecent* indicates if it is the most recent boundary shapefile that should be used (in case there were multiple ones). If FALSE and if there are multiple available inputs, we are interactively asked to select the input based on download time. Finally, the logical parameter *alwaysSet* indicates whether the projected coordinate reference system should always be set, even it it has already been set. If FALSE and if the projected coordinate reference system has already been set we are interactively asked whether we want to set it again or not.

```{r set_projection, eval=FALSE}
set_projection(mainPath, country, mostRecent = TRUE, alwaysSet = TRUE, bestCRS = TRUE)
```

Let's have a look at the project config.txt file. It is used to retrieve the project parameters in other functions and should not be modified manually.

![](configtxt.png)

The function also has projected the boundary shapefile and we can observe how the directory structure has changed. The sub-folder names refer to the time (year, month, day, hour, minute, second, all together) at which the input was downloaded or the process was run. In the following example, we observe that the raw boundary shapefile was downloaded at 2022-05-27 14:09:56 and was processed at 2022-05-27 14:11:02.

![](tree_after_setProj.png)

### Filter the health facilities and create a point shapefile

This section is only compatible with the HeRAMS Excel tables. If we are not working with HeRAMS data, we can just skip this part and use the *copy_input* function to copy a health facility shapefile into an appropriate sub-folder (it will copy the input to e.g. /vFacilities/20220524103021/raw).

If we are working with HeRAMS data, let's filter the health facilities from our raw health facility table with the *filter_hf*  function and create a point shapefile of the filtered facilities with the *create_hf_facilities* function. 

The function *filter_hf* requires the main project folder and the country folder name. Besides, it also requires the path to the raw Excel table (if NULL, we are asked whether we want to take fictitious example data from Switzerland). Three other parameters are optional: scenario, mostRecentObs, barriers, partners, and defaultParameters

To understand these parameters, let's see how this function works.

#### scenario
Based on a set of pre-defined table parameters (we are asked whether we would like to modify them when running the function or not), we are interactively asked to select the health facilities that we want to keep based on available attribute values. After a first filter on main information (e.g. health facility type) and operationality (status, building condition, functionality and accessibility), we are asked whether we would like to focus on specific health services. The overall information regarding the analysis scenario is recorded in a text file (selected_hf.txt) which should not be modified manually. A new scenario folder is created for any new set of selection criteria. The first time this function is run, a first scenario folder is created. The next times, we have two options: 1) We leave the scenario parameter NULL; we will be then interactively asked to select the health facility based on specific attributes, and if the selection criteria are identical than in any previous run, the corresponding scenario folder will be used as output folder. If not, a new scenario will be created. 2) We specify an already created scenario folder, and the function will apply the selection criteria linked with this scenario.

#### mostRecentObs
This logical parameter indicates whether we would like to take into account the most recent observation for each health facility when we have multiple responses. If mostRecentObs = FALSE, we can interactively select among three options, 1) most recent, 2) date limit (the most recent before a specific date), or case by case. The selected option is recorded in a text file (time_frame.txt) which should not be modified manually.

#### barriers
This logical parameter indicates whether we would like to also filter the health facilities on the causes of possible impairment such as dysfunctionality, unavailable services usually provided, etc. when impaired facilities are selected.

#### partners
This logical parameter indicates whether we would like to also filter the health facilities on the different possible supporting partners, when it applies.

#### defaultParameters
This logical parameter indicates whether the function should use the default HeRAMS table parameters for (column names, key code values, etc.). If is set to FALSE, we can interactively modify them. To access the default values, use HeRAMS_table_parameters, HeRAMS_impairment_values, HeRAMS_partnership_values, HeRAMS_stop_filtering().

Let's see an example with the fictitious example data. The following command shows the the six first rows of the table and some of the main variables.

```{r fictitious}
inAccessMod::fictitious_herams_data_txt[1:6, c("last_synced", "subject_id", "date", "MoSD4", "CONDB", "HFFUNCT", "HFACC", "MoSDGPS_SQ001", "MoSDGPS_SQ002")]
```


```{r filter_hf, eval=FALSE}
filter_hf(mainPath, country, pathTable = NULL, barriers = FALSE, mostRecentObs = TRUE)
```

A folder "scenario001" was created in which we find the text file called "selected_hf.txt" with the selection criteria and a sub-folder whose name refers to the time at which the table was filtered. In this sub-folder, there is another text file called "time_frame.txt" informing about how the multiple responses per facility were handled, and a "raw" sub-folder that contains the filtered table.

![](tree_vFacilities1.png)

![](selected_hf.png)

![](time_frame.png)

Let's say that we would like to re-run the function with different selection criteria.

```{r filter_hf2, eval=FALSE}
filter_hf(mainPath, country, pathTable = NULL, scenario = NULL, mostRecentObs = TRUE)
```

![](tree_vFacilities2.png)

We can see that we have now two scenario sub-folders. Running again this function with the same criteria used in "scenario001" would create a new sub-folder within "scenario001" and a new time_frame.txt file. 

Now let's create a shapefile from the first health facility filtered table. The function checks if there are missing coordinates and if the facilities fall within the country boundary. If so, we are asked whether we want to add/correct them or remove the corresponding facilities. The *mostRecentBoundaries* parameter indicates if the most recent downloaded boundaries has to be used. If FALSE and if there are multiple available boundary shapefiles, we are interactively asked to select the input based on file creation time. If *rmNA* and *rmOut* are TRUE, the function removes the facilities that have missing coordinates or that fall outside the country boundaries and create text files informing about the removed facilities. Finally the *lonlat* indicates if the coordinates reflect the WGS84 longitude and latitude. If FALSE, an *epsg* code is requires. Finally, the *scenario* parameter allows us to directly specify the sub-project from which we want to vectorize the health facilities. If NULL, we are interactively asked to choose the sub-project from the available ones (during this process we have the option of printing each sub-project selection criteria in the console).

```{r create_hf_shp, eval=FALSE}
create_hf_shapefile(mainPath, country, mostRecentBoundaries = TRUE, lonlat = TRUE, rmNA = TRUE, rmOut = TRUE, scenario = "001")
```

### Download open source layers

#### DEM

This function allows us to download a SRTM 90m resolution (3 arc-seconds) DEM for the entire country and copies it to its corresponding folder. The SRTM tiles to be downloaded are selected based on the extent of the boundary shapefile. If there are multiple tiles, a mosaic is produced. If *alwaysDownload* is TRUE, the raster will always be downloaded, even if it has already been downloaded? If FALSE and if the raster has already been downloaded we are interactively asked whether we want to download it again or not. And the *mostRecent* logical parameter indicates if the most recent boundary shapefile should be selected to define the required DEM tiles?

```{r DEM, eval=FALSE}
download_dem(mainPath, country, alwaysDownload = TRUE, mostRecent = TRUE)
```

#### Population raster

This function allows us to download a population raster from the World Pop FTP and copy it to its corresponding folder. It allows to interactively navigate through the folders and select the population raster to be downloaded. The ISO code retrieved internally is used to match the country FTP folder when available. If *alwaysDownload* is TRUE, the raster is always be downloaded, even if it has already been downloaded? If FALSE and if the raster has already been downloaded we are interactively asked whether we want to download it again or not.

```{r pop, eval=FALSE}
download_population(mainPath, country, alwaysDownload = TRUE)
```

![](ftp.png)

#### Landcover

This function allows us to download the Land Cover 100 m from the Copernicus Global Land Service and copy it to its corresponding folder. The function downloads the landcover tiles from the AWS cloud and determines the file names based on the extent of the boundary shapefile. If there are multiple tiles, it produces a mosaic. If *alwaysDownload* is TRUE, the raster is always be downloaded, even if it has already been downloaded? If FALSE and if the raster has already been downloaded we are interactively asked whether we want to download it again or not. And the *mostRecent* logical parameter indicates if the most recent boundary shapefile should be selected to define the required landcover tiles? 

```{r landcover, eval=FALSE}
download_landcover(mainPath, country, alwaysDownload = TRUE, mostRecent = TRUE)
```

#### Open Street Maps

This function allows us to download the Open Street Map shapefiles corresponding to 'roads', 'rivers' or any other natural feature and copy them to their corresponding folders. The parameter *x* represents the target layer. Can be 'roads', 'waterLines' or 'naturalPolygons'. The logical parameter countryName indicates if the country name should be used to match with the osm.pbf file in the OSM server? If FALSE, it is the extent of the boundary shapefile that is matched with the osm.pbf file in the Geofabrik's free download server. Matching by name is usually much faster and *countryName* should be always set TRUE, unless the country name is complex and not recognized by the server. The *mostRecent* parameter is ignored if *countryName* is TRUE. If x = "roads" and defaultClasses is TRUE, only the official OSM road classes are kept. For waterLines and naturalPolygons, default classes are river and water, respectively. If defaultClasses is FALSE, we can select the available classes we would like to keep.

```{r roads, eval=FALSE}
download_osm(x = "roads", mainPath, country, alwaysDownload = FALSE, countryName = TRUE, mostRecent = NULL, defaultClasses = TRUE)
```

```{r waterLines, eval=FALSE}
download_osm("waterLines", mainPath, country, alwaysDownload = TRUE, countryName = TRUE, mostRecent = NULL, defaultClasses = FALSE)
```

As for the other OSM layers, we are asked which categories we want to keep.

![](categories.png)

At any time, we can check which inputs (either 'raw' or 'processed') are available and which are not available.

```{r checkInputs, eval=FALSE}
check_inputs(mainPath, country, type = "raw")
```

![](checkInputs.png)

Let's download the lakes from OSM before processing the inputs.

```{r naturalPolyg, eval=FALSE}
download_osm("naturalPolygons", mainPath, country, alwaysDownload = TRUE, countryName = TRUE, mostRecent = NULL)
```

### Process layers

The following function allows to process any input layer and copy it to its corresponding folder. A 'processed' boundary shapefile is required for processing any other inputs. A 'processed' population raster is required for processing any other raster. These conditions are taken into account and the processing of these layers is performed even if they are not selected and if 'processed' layers are not available. These are the specific parameters:

* *selectedInputs* character; vector indicating the inputs to be processed. Raw inputs must be available. Argument can be set to "All" to consider all the available 'raw' inputs. If NULL, the user is interactively asked to select the available inputs to be processed.
* *mostRecent* logical; should the most recent input be selected? If FALSE and if there are multiple available inputs, the user is interactively asked to select the input based on file creation time.
* *alwaysProcess* logical; should always the input be processed? If *alwaysProcess* = FALSE and if the input has already been processed, the user is interactively asked whether they want to process it or not.
* *defaultMethods* logical; should be the default methods be used for projecting and resampling, respectively. For the population raster, these are the 'bilinear' method for projecting and the 'sum' or the 'bilinear' for the resampling,  depending on if the new resolution is lower or higher. For the landcover raster, the 'near' method is used for both the  projection and resampling. For the the DEM, the 'bilinear' method is used for both the projection and resampling. If FALSE, the user is interactively asked to choose the methods from a list of options.
* *changeRes* logical; does the user want to change the raster resolution of the population raster? If NULL, the resolution  is printed and it is interactively asked the user if they want to change it. IF FALSE, there is no resampling.
* *newRes* numeric; new resolution in meters. Ignored if the changeRes is FALSE. If NULL and if *changeRes* is TRUE, the user is interactively asked to provide the new resolution.
* *popCorrection* logical; should the raster correction algorithm be run. If it is NULL, the user is interactively asked whether they want to run it or not.
* *gridRes* numeric; the resolution of the grid shapefile used for correcting the raster. Ignored if *popCorrection* is FALSE. If NULL and popCorrection is TRUE, the user is interactively asked to provide the grid resolution.

```{r process_inputs, eval=FALSE}
process_inputs(mainPath, country, selectedInputs = "All", mostRecent = TRUE, alwaysProcess = TRUE, defaultMethods = TRUE, changeRes = TRUE, newRes = 100, popCorrection = TRUE, gridRes = 3000)
```

Let's have a look at the log.txt file

![](log.png)

### Processed input compiling

Finally, to facilitate the importation of processed inputs into AccessMod, we can use the *compile_processed_data* function. It compiles the available processed layers and copy them to a new folder called "zToAccessMod". Different runs of this function will create different sub-folder within the "zToAccessMod" folder. 

When *mostRecent* is TRUE, it is the most recent processed layer that is copied into the new folder.

```{r compile, eval=FALSE}
compile_processed_data (mainPath, country, mostRecent = TRUE)
```

![](zToAccessMod.png)
